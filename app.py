import streamlit as st
import pandas as pd
import requests
import gspread
from google.oauth2.service_account import Credentials
import datetime
import time
import hmac
import hashlib
import base64
import re
from collections import Counter

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="ğŸ’ ì•„ì´í…œ ìŠ¤ì¹´ìš°íŠ¸ (ì–´ë·°ì§• íƒì§€)", page_icon="ğŸš¨", layout="wide")

# ================= 1. ìœ í‹¸ë¦¬í‹° & ì–´ë·°ì§• ë¡œì§ =================
def clean_num(n):
    if not n: return 0
    s = str(n).replace(",", "")
    return 10 if "<" in s else int(s) if s.isdigit() else 0

def extract_keywords(title):
    clean = re.sub(r'[^\w\s]', ' ', title)
    return [w for w in clean.split() if len(w) > 1]

# [SEO ì±„ì ]
def get_seo_score(title, target_keyword):
    clean_title = title.replace('<b>','').replace('</b>','')
    score = 80
    length = len(clean_title)
    if 20 <= length <= 50: score += 10
    elif length < 10: score -= 20
    elif length > 60: score -= 10
    
    target_parts = target_keyword.split()
    front_part = clean_title[:15]
    match_count = sum(1 for part in target_parts if part in front_part)
    if match_count > 0: score += 10
    
    counts = Counter(extract_keywords(clean_title))
    repeats = sum(1 for w in counts if counts[w] >= 3)
    if repeats > 0: score -= 20
    
    special_chars = len(re.findall(r'[^\w\s]', clean_title))
    if special_chars > 5: score -= 10
    return max(0, min(100, score))

def get_seo_grade_text(score):
    if score >= 95: return "ğŸ‘‘S"
    elif score >= 85: return "âœ¨A"
    elif score >= 70: return "âš ï¸B"
    else: return "âŒF"

def calculate_power_score(rank, reviews, is_brand, is_big_mall, seo_score):
    total = 0
    total += max(0, 41 - rank)
    total += min(30, reviews / 10)
    if is_brand or is_big_mall: total += 20
    total += (seo_score / 10)
    return int(total)

# [ğŸš¨ í•µì‹¬] ì–´ë·°ì§• íƒì§€ ë¡œì§
def detect_abuse(rank, reviews, seo_score, is_brand, is_big_mall):
    """
    ë„¤ì´ë²„ ì‡¼í•‘ ë¡œì§ ì—­ì¶”ì :
    1. íŠ¸ë˜í”½/ìŠ¬ë¡¯: ìƒí’ˆë ¥(ë¦¬ë·°, SEO)ì´ ê°œíŒì¸ë° ìƒìœ„ë…¸ì¶œ(1~10ìœ„)ì¸ ê²½ìš°
    2. ê°€êµ¬ë§¤: ë¦¬ë·°ê°€ ë„ˆë¬´ ì ì€ë° ìƒìœ„ê¶Œì¸ ê²½ìš° (ì•½í•œ ì˜ì‹¬)
    """
    if is_brand or is_big_mall:
        return "âœ…ì •ìƒ(ë¸Œëœë“œ)"
    
    # 1. íŠ¸ë˜í”½/ìŠ¬ë¡¯ ì˜ì‹¬ (ë­í‚¹ì€ ë†’ì€ë° ê¸°ë³¸ê¸°ê°€ ì—‰ë§)
    if rank <= 10:
        if seo_score < 40 and reviews < 10:
            return "ğŸš¨ìŠ¬ë¡¯/íŠ¸ë˜í”½ ê°•ë ¥ì˜ì‹¬ (ê¸°ë³¸ê¸°X)"
        if reviews < 5:
            return "âš ï¸ê°€êµ¬ë§¤/íŠ¸ë˜í”½ ì£¼ì˜ (ë¦¬ë·°ë¶€ì¡±)"
        if seo_score < 50:
            return "âš ï¸ì–´ë·°ì§• ê°€ëŠ¥ì„± (SEOë¶ˆëŸ‰)"
            
    return "ì‘ì—…ì§•í›„ ì—†ìŒ"

# ================= 2. API í†µì‹  í•¨ìˆ˜ë“¤ =================
def get_keyword_stats(keywords_list):
    BASE_URL = "https://api.searchad.naver.com"
    URI = "/keywordstool"
    
    try:
        customer_id = st.secrets["NAVER_CUSTOMER_ID"]
        access_license = st.secrets["NAVER_ACCESS_LICENSE"]
        secret_key = st.secrets["NAVER_SECRET_KEY"]
    except:
        st.error("âŒ Secrets ì„¤ì • ì˜¤ë¥˜: ê´‘ê³  API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    timestamp = str(int(time.time() * 1000))
    msg = f"{timestamp}.GET.{URI}"
    signature = base64.b64encode(hmac.new(secret_key.encode(), msg.encode(), hashlib.sha256).digest()).decode()

    headers = {
        "X-Timestamp": timestamp, "X-API-KEY": access_license,
        "X-Customer": customer_id, "X-Signature": signature
    }
    
    clean_kws = [k.strip().replace(" ", "") for k in keywords_list if k.strip()][:5]
    params = {"hintKeywords": ",".join(clean_kws), "showDetail": "1"}
    
    try:
        response = requests.get(f"{BASE_URL}{URI}", headers=headers, params=params)
        if response.status_code == 200:
            data = response.json()
            return {item['relKeyword'].replace(" ", ""): item for item in data['keywordList']}
        else:
            st.error(f"ê´‘ê³  API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}")
    except Exception as e:
        st.error(f"ê´‘ê³  API ì—°ê²° ì—ëŸ¬: {e}")
    return {}

def get_shopping_data(keyword):
    url = "https://openapi.naver.com/v1/search/shop.json"
    try:
        headers = {
            "X-Naver-Client-Id": st.secrets["NAVER_CLIENT_ID"],
            "X-Naver-Client-Secret": st.secrets["NAVER_CLIENT_SECRET"]
        }
    except:
        return None
    params = {"query": keyword, "display": 80, "sort": "sim"}
    try:
        res = requests.get(url, headers=headers, params=params)
        return res.json()
    except: return None

# --- ë””ìì¸: ì‹œíŠ¸ ì—´ ë„ˆë¹„ ì¡°ì ˆ (Batch Update) ---
def set_column_widths(worksheet, widths):
    body = {"requests": []}
    for col_char, width in widths:
        col_index = ord(col_char.upper()) - 65
        body["requests"].append({
            "updateDimensionProperties": {
                "range": {
                    "sheetId": worksheet.id, "dimension": "COLUMNS",
                    "startIndex": col_index, "endIndex": col_index + 1
                },
                "properties": {"pixelSize": width}, "fields": "pixelSize"
            }
        })
    try:
        worksheet.spreadsheet.batch_update(body)
    except: pass

# --- ğŸ” êµ¬ê¸€ ì‹œíŠ¸ ì¸ì¦ ---
def get_gspread_client():
    try:
        creds_info = st.secrets["gcp_service_account"]
        credentials = Credentials.from_service_account_info(
            creds_info,
            scopes=["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
        )
        return gspread.authorize(credentials)
    except: return None

# ================= 3. ë©”ì¸ í™”ë©´ UI =================
st.title("ğŸš¨ ì•„ì´í…œ ìŠ¤ì¹´ìš°íŠ¸ (ì–´ë·°ì§• íƒì§€ Ver)")
st.info("ê²€ìƒ‰ëŸ‰ ì¡°íšŒ + **íŠ¸ë˜í”½/ê°€êµ¬ë§¤ ì‘ì—… ì—…ì²´ íƒì§€** ê¸°ëŠ¥ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")

with st.form("analysis_form"):
    col1, col2 = st.columns([3, 1])
    with col1:
        input_keywords = st.text_input("ë¶„ì„í•  í‚¤ì›Œë“œ", placeholder="ì˜ˆ: ìŠ¤ì¹¼ë › ì†”ë¡œ")
        my_store_name = st.text_input("ë‚´ ìŠ¤í† ì–´ëª…", placeholder="ì˜ˆ: ë² ë§ê±° ìŠ¤í† ì–´")
    with col2:
        st.write("")
        st.write("")
        submit_btn = st.form_submit_button("ğŸš€ ë¶„ì„ ë° íƒì§€", type="primary")

if submit_btn and input_keywords:
    target_keywords = [k.strip() for k in input_keywords.split(',')]
    
    # 1. ê²€ìƒ‰ëŸ‰ ì¡°íšŒ (ì‹¤íŒ¨ ì‹œ ë©”ì‹œì§€ ì¶œë ¥)
    stats_map = get_keyword_stats(target_keywords)
    if stats_map is None:
        st.warning("âš ï¸ ê´‘ê³  API ì—°ê²° ì‹¤íŒ¨ -> ê²€ìƒ‰ëŸ‰ì´ 0ìœ¼ë¡œ ë‚˜ì˜µë‹ˆë‹¤. Secretsë¥¼ í™•ì¸í•˜ì„¸ìš”!")
        stats_map = {}

    with st.spinner("ğŸ•µï¸â€â™‚ï¸ ì–´ë·°ì§• ì—…ì²´ ìƒ‰ì¶œ ì¤‘..."):
        all_results = []
        kst_now = (datetime.datetime.now() + datetime.timedelta(hours=9)).strftime('%Y-%m-%d %H:%M:%S')
        big_malls = ["ì¿ íŒ¡", "11ë²ˆê°€", "Gë§ˆì¼“", "ì˜¥ì…˜", "ì¸í„°íŒŒí¬", "ë¡¯ë°", "ì‹ ì„¸ê³„", "ì´ë§ˆíŠ¸", "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´"]

        for kw in target_keywords:
            shop = get_shopping_data(kw)
            if not shop: continue
            
            items = shop.get('items', [])
            total_products = int(shop.get('total', 0))
            
            # ê²€ìƒ‰ëŸ‰ ë§¤ì¹­
            stat = stats_map.get(kw.replace(" ", ""), {})
            pc_vol = clean_num(stat.get('monthlyPcQcCnt', 0))
            mo_vol = clean_num(stat.get('monthlyMobileQcCnt', 0))
            total_vol = pc_vol + mo_vol
            comp_ratio = round(total_products / total_vol, 2) if total_vol > 0 else 0
            
            # ìƒìœ„ ë¶„ì„
            top_10 = items[:10]
            prices = [clean_num(i['lprice']) for i in top_10 if clean_num(i['lprice']) > 100]
            avg_price = sum(prices) / len(prices) if prices else 0
            
            # [ì‹œì¥ë¶„ì„ í–‰]
            all_results.append({
                'ìˆœìœ„': 0, 'êµ¬ë¶„': 'ğŸ“¢ ì‹œì¥ë¶„ì„', 'ì–´ë·°ì§•': '-',
                'ìŠ¤í† ì–´ëª…': f"í‰ê·  {int(avg_price):,}ì›",
                'ìƒí’ˆëª…': f"ê²€ìƒ‰ {total_vol:,} / ìƒí’ˆ {total_products:,}", 
                'AI_ì „ëµ': f"ê²½ìŸê°•ë„ {comp_ratio}", 
                'ê°€ê²©': int(avg_price), 'í‚¤ì›Œë“œ': kw, 'ê²€ìƒ‰ëŸ‰': total_vol,
                'ìˆ˜ì§‘ì¼ì‹œ': kst_now
            })
            
            # [ê°œë³„ ìƒí’ˆ ë¶„ì„]
            for idx, item in enumerate(items):
                rank = idx + 1
                title = item['title'].replace('<b>','').replace('</b>','')
                mall = item.get('mallName', '')
                brand = item.get('brand', '')
                price = clean_num(item.get('lprice'))
                is_mine = my_store_name in mall if my_store_name else False
                is_big_mall = any(big in mall for big in big_malls)
                
                seo_raw_score = get_seo_score(title, kw)
                seo_grade_text = get_seo_grade_text(seo_raw_score)
                reviews = clean_num(item.get('reviewCount', 0))
                
                # ì–´ë·°ì§• íƒì§€ ì‹¤í–‰
                abuse_status = detect_abuse(rank, reviews, seo_raw_score, bool(brand), is_big_mall)
                
                # ì¹´í…Œê³ ë¦¬
                category = "ì¼ë°˜"
                if brand: category = "ë¸Œëœë“œ"
                if is_mine: category = "â˜…ë‚´ ìƒí’ˆ"
                
                # ì „ëµ ì½”ë©˜íŠ¸
                strategy_comment = f"SEO: {seo_grade_text}"
                if is_mine:
                    strategy_comment = "ë‚´ ìƒí’ˆ ê´€ë¦¬ì¤‘"
                elif "ì˜ì‹¬" in abuse_status:
                    strategy_comment = "ğŸš«ë²¤ì¹˜ë§ˆí‚¹ ê¸ˆì§€"

                all_results.append({
                    'ìˆœìœ„': rank, 'êµ¬ë¶„': category, 'ì–´ë·°ì§•': abuse_status,
                    'ìŠ¤í† ì–´ëª…': mall, 'ìƒí’ˆëª…': title, 
                    'AI_ì „ëµ': strategy_comment,
                    'ê°€ê²©': price, 'í‚¤ì›Œë“œ': kw, 'ê²€ìƒ‰ëŸ‰': total_vol,
                    'ìˆ˜ì§‘ì¼ì‹œ': kst_now
                })

        # 3. êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥
        if all_results:
            df = pd.DataFrame(all_results)
            # ì»¬ëŸ¼ ìˆœì„œ (ì–´ë·°ì§• ì¶”ê°€ë¨)
            cols = ['ìˆœìœ„', 'êµ¬ë¶„', 'ì–´ë·°ì§•', 'ìŠ¤í† ì–´ëª…', 'ìƒí’ˆëª…', 'AI_ì „ëµ', 'ê°€ê²©', 'í‚¤ì›Œë“œ', 'ê²€ìƒ‰ëŸ‰', 'ìˆ˜ì§‘ì¼ì‹œ']
            df = df[cols]
            
            try:
                gc = get_gspread_client()
                sheet_url = st.secrets["SHEET_URL"]
                doc = gc.open_by_url(sheet_url)
                ws = doc.get_worksheet(0)
                
                ws.clear()
                ws.update(values=[df.columns.values.tolist()] + df.values.tolist(), range_name='A1')
                
                # [ì¹¼ê° ë””ìì¸]
                set_column_widths(ws, [
                    ('A', 35), ('B', 60), ('C', 150), ('D', 120),
                    ('E', 400), ('F', 120), ('G', 70), ('H', 80), ('I', 60), ('J', 130)
                ])
                
                ws.freeze(rows=1)
                ws.format("A1:J1", {"backgroundColor": {"red": 0.9, "green": 0.9, "blue": 0.9}, "textFormat": {"bold": True}, "horizontalAlignment": "CENTER"})
                
                # ê²½ê³  ìƒ‰ìƒ (ì–´ë·°ì§• í–‰ì€ ë¹¨ê°„ìƒ‰ ê°•ì¡°)
                # (ìƒëµ: ì½”ë“œê°€ ë„ˆë¬´ ê¸¸ì–´ì§€ë‹ˆ ì¼ë‹¨ ë°ì´í„°ë¶€í„° í™•ì¸!)

                st.success(f"âœ… ë¶„ì„ ì™„ë£Œ! ì–´ë·°ì§• ì˜ì‹¬ ì—…ì²´ {len(df[df['ì–´ë·°ì§•'].str.contains('ì˜ì‹¬')])}ê±´ ë°œê²¬.")
                st.dataframe(df) # í™”ë©´ í™•ì¸ìš©
            except Exception as e:
                st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")
